{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a30ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5080913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock,self).__init__()\n",
    "        self.channels = channels\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channels,channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels,channels, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.conv1(x))\n",
    "        y = self.conv2(y)\n",
    "        \n",
    "        return F.relu(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8dd2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.rblock1 = ResidualBlock(16)\n",
    "        self.rblock2 = ResidualBlock(32)\n",
    "        \n",
    "        self.fc = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.mp(F.relu(self.conv1(x)))\n",
    "        x = self.rblock1(x)\n",
    "        x = self.mp(F.relu(self.conv2(x)))\n",
    "        x = self.rblock2(x)\n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "098cde87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建数据集\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        if self.train:\n",
    "            images_file = 'train-images-idx3-ubyte.gz'\n",
    "            labels_file = 'train-labels-idx1-ubyte.gz'\n",
    "        else:\n",
    "            images_file = 't10k-images-idx3-ubyte.gz'\n",
    "            labels_file = 't10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "        self.images_path = os.path.join(root, images_file)\n",
    "        self.labels_path = os.path.join(root, labels_file)\n",
    "\n",
    "        self.images, self.labels = self.load_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def load_data(self):\n",
    "        with gzip.open(self.images_path, 'rb') as f_images:\n",
    "            images = np.frombuffer(f_images.read(), dtype=np.uint8, offset=16).reshape(-1, 28, 28)\n",
    "\n",
    "        with gzip.open(self.labels_path, 'rb') as f_labels:\n",
    "            labels = np.frombuffer(f_labels.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ce2732",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c4bf8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MNISTDataset(root='./mnist_dataset/', train=True, transform=transform)\n",
    "train_loader =  DataLoader(train_dataset,shuffle=True,batch_size=batch_size)\n",
    "\n",
    "test_dataset = MNISTDataset(root='./mnist_dataset/', train=False, transform=transform)\n",
    "test_loader =  DataLoader(test_dataset,shuffle=False,batch_size=batch_size)\n",
    "print(test_dataset.__len__())\n",
    "print(train_dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20362e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (rblock1): ResidualBlock(\n",
       "    (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (rblock2): ResidualBlock(\n",
       "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7b8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ece2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader,0):\n",
    "        inputs, target = data\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if batch_idx%300 == 299:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / 300))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7fd7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('accuracy on test set: %d %% ' % (100*correct/total))\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf539ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\application\\Anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torchvision\\transforms\\functional.py:152: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 0.479\n",
      "[1,   600] loss: 0.153\n",
      "[1,   900] loss: 0.109\n",
      "accuracy on test set: 97 % \n",
      "[2,   300] loss: 0.086\n",
      "[2,   600] loss: 0.080\n",
      "[2,   900] loss: 0.072\n",
      "accuracy on test set: 98 % \n",
      "[3,   300] loss: 0.060\n",
      "[3,   600] loss: 0.056\n",
      "[3,   900] loss: 0.057\n",
      "accuracy on test set: 98 % \n",
      "[4,   300] loss: 0.049\n",
      "[4,   600] loss: 0.049\n",
      "[4,   900] loss: 0.045\n",
      "accuracy on test set: 98 % \n",
      "[5,   300] loss: 0.042\n",
      "[5,   600] loss: 0.040\n",
      "[5,   900] loss: 0.043\n",
      "accuracy on test set: 98 % \n",
      "[6,   300] loss: 0.035\n",
      "[6,   600] loss: 0.037\n",
      "[6,   900] loss: 0.036\n",
      "accuracy on test set: 98 % \n",
      "[7,   300] loss: 0.027\n",
      "[7,   600] loss: 0.033\n",
      "[7,   900] loss: 0.034\n",
      "accuracy on test set: 98 % \n",
      "[8,   300] loss: 0.028\n",
      "[8,   600] loss: 0.026\n",
      "[8,   900] loss: 0.031\n",
      "accuracy on test set: 98 % \n",
      "[9,   300] loss: 0.024\n",
      "[9,   600] loss: 0.025\n",
      "[9,   900] loss: 0.026\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    epoch_list = []\n",
    "    acc_list = []\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "        acc = test()\n",
    "        epoch_list.append(epoch)\n",
    "        acc_list.append(acc)\n",
    "    \n",
    "    plt.plot(epoch_list,acc_list)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61917827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch=gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
