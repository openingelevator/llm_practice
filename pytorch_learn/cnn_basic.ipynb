{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "942d98ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN常见的术语\n",
    "# channel，通道数，一般的RGB图像即为3通道数图像，在进行卷积时，通过设置卷积核的数量，可以调整输出的通道数\n",
    "# 通常卷积核会对一张图片的多个通道进行卷积操作，之后进行图像信息融合（一般为求和），得到一个通道输出的图像\n",
    "# 一般地，如果是3通道的图片，需要采用3个卷积核分别进行操作，计算完之后进行融合。\n",
    "# 如果想要得到m个通道的输出图像，那么就需要m个批次的卷积核组，每个组卷积核数量为原图像的通道数\n",
    "# maxpooling部分，主要用来实现对图像的下采样，通过保留局部最突出的信息，对图像进行压缩\n",
    "# 一般指定maxpooling层的大小为2，意味着在2×2的单元格中找出最大值，如一个4×4大小的图像通过maxpooling操作之后，尺寸会变化成2×2\n",
    "# patch指由一张图片多个通道组成的批量数据\n",
    "# stride步长，也就是每次卷积核移动的grid数\n",
    "# padding指在原图片四周边框所添加的像素，一般为0，或者取邻域的最大值，通常当padding=1时，使用3×3的卷积核卷积后图像的大小不改变\n",
    "# batch，在pytorch当中，输入数据的格式一般为（batch，channe，width，height），batch指输入数据的批次，单位为batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd0e43d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f69ba0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        if self.train:\n",
    "            images_file = 'train-images-idx3-ubyte.gz'\n",
    "            labels_file = 'train-labels-idx1-ubyte.gz'\n",
    "        else:\n",
    "            images_file = 't10k-images-idx3-ubyte.gz'\n",
    "            labels_file = 't10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "        self.images_path = os.path.join(root, images_file)\n",
    "        self.labels_path = os.path.join(root, labels_file)\n",
    "\n",
    "        self.images, self.labels = self.load_data()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def load_data(self):\n",
    "        with gzip.open(self.images_path, 'rb') as f_images:\n",
    "            images = np.frombuffer(f_images.read(), dtype=np.uint8, offset=16).reshape(-1, 28, 28)\n",
    "\n",
    "        with gzip.open(self.labels_path, 'rb') as f_labels:\n",
    "            labels = np.frombuffer(f_labels.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96082c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0de0369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MNISTDataset(root='./mnist_dataset/', train=True, transform=transform)\n",
    "train_loader =  DataLoader(train_dataset,shuffle=True,batch_size=batch_size)\n",
    "\n",
    "test_dataset = MNISTDataset(root='./mnist_dataset/', train=False, transform=transform)\n",
    "test_loader =  DataLoader(test_dataset,shuffle=False,batch_size=batch_size)\n",
    "print(test_dataset.__len__())\n",
    "print(train_dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "508d7920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Model(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=320, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model,self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2 = torch.nn.Conv2d(10,20,kernel_size=5)\n",
    "        self.pool = torch.nn.MaxPool2d(2)\n",
    "        self.fc = torch.nn.Linear(320,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        x = x.view(batch_size,-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = CNN_Model()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7254db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d880df3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader,0):\n",
    "        inputs, target = data\n",
    "        inputs, target = inputs.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if batch_idx%300 == 299:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / 300))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0446dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('accuracy on test set: %d %% ' % (100*correct/total))\n",
    "    return correct/total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4644a312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\application\\Anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torchvision\\transforms\\functional.py:152: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 0.555\n",
      "[1,   600] loss: 0.180\n",
      "[1,   900] loss: 0.136\n",
      "accuracy on test set: 96 % \n",
      "[2,   300] loss: 0.107\n",
      "[2,   600] loss: 0.102\n",
      "[2,   900] loss: 0.086\n",
      "accuracy on test set: 97 % \n",
      "[3,   300] loss: 0.078\n",
      "[3,   600] loss: 0.078\n",
      "[3,   900] loss: 0.069\n",
      "accuracy on test set: 98 % \n",
      "[4,   300] loss: 0.063\n",
      "[4,   600] loss: 0.063\n",
      "[4,   900] loss: 0.065\n",
      "accuracy on test set: 98 % \n",
      "[5,   300] loss: 0.050\n",
      "[5,   600] loss: 0.054\n",
      "[5,   900] loss: 0.059\n",
      "accuracy on test set: 98 % \n",
      "[6,   300] loss: 0.048\n",
      "[6,   600] loss: 0.051\n",
      "[6,   900] loss: 0.052\n",
      "accuracy on test set: 98 % \n",
      "[7,   300] loss: 0.044\n",
      "[7,   600] loss: 0.048\n",
      "[7,   900] loss: 0.042\n",
      "accuracy on test set: 98 % \n",
      "[8,   300] loss: 0.045\n",
      "[8,   600] loss: 0.041\n",
      "[8,   900] loss: 0.039\n",
      "accuracy on test set: 98 % \n",
      "[9,   300] loss: 0.037\n",
      "[9,   600] loss: 0.040\n",
      "[9,   900] loss: 0.039\n",
      "accuracy on test set: 98 % \n",
      "[10,   300] loss: 0.037\n",
      "[10,   600] loss: 0.036\n",
      "[10,   900] loss: 0.036\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    epoch_list = []\n",
    "    acc_list = []\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "        acc = test()\n",
    "        epoch_list.append(epoch)\n",
    "        acc_list.append(acc)\n",
    "    \n",
    "    plt.plot(epoch_list,acc_list)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e8246c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch=gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
